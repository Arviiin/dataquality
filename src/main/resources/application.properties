#绿色，已经加入版本控制暂未提交；
#红色，未加入版本控制；
#蓝色，加入版本控制，已提交，有改动；
#白色，加入版本控制，已提交，无改动；
#灰色：版本控制已忽略文件。
#以上为版本控制颜色
##################    JDBC 配置    ################
#数据库配置
#spring.datasource.druid.type=com.alibaba.druid.pool.DruidDataSource
#spring.datasource.driverClassName = com.mysql.jdbc.Driver
##spring.datasource.url=jdbc:mysql://localhost:3306/dataquality?useUnicode=true&characterEncoding=utf-8&useSSL=false
#spring.datasource.url=jdbc:mysql://47.98.210.231:3306/dataquality?useUnicode=true&characterEncoding=utf-8&useSSL=false
#spring.datasource.username=root
#spring.datasource.password=2171821

###################    连接池配置    ################
##连接池建立时创建的初始化连接数
#spring.datasource.druid.initial-size=5
##连接池中最大的活跃连接数
#spring.datasource.druid.max-active=12
##连接池中最小的活跃连接数
#spring.datasource.druid.min-idle=5
## 配置获取连接等待超时的时间
#spring.datasource.druid.max-wait=60000
## 打开PSCache，并且指定每个连接上PSCache的大小
#spring.datasource.druid.pool-prepared-statements=true
#spring.datasource.druid.max-pool-prepared-statement-per-connection-size=20
##spring.datasource.druid.max-open-prepared-statements= #和上面的等价
#spring.datasource.druid.validation-query=SELECT 1 FROM DUAL
#spring.datasource.druid.validation-query-timeout=30000
##是否在获得连接后检测其可用性
#spring.datasource.druid.test-on-borrow=false
##是否在连接放回连接池后检测其可用性
#spring.datasource.druid.test-on-return=false
##是否在连接空闲一段时间后检测其可用性
#spring.datasource.druid.test-while-idle=true
##spring.datasource.druid.time-between-eviction-runs-millis=
##spring.datasource.druid.min-evictable-idle-time-millis=
##spring.datasource.druid.max-evictable-idle-time-millis=

#多数据源配置
spring.datasource.one.url = jdbc:mysql://47.98.210.231:3306/dataquality?useUnicode=true&characterEncoding=utf-8&useSSL=false
spring.datasource.one.username = root
spring.datasource.one.password = 2171821
spring.datasource.one.type = com.alibaba.druid.pool.DruidDataSource
spring.datasource.one.driver-class-name = com.mysql.jdbc.Driver


spring.datasource.two.url = jdbc:mysql://localhost:3306/data-quality?useUnicode=true&characterEncoding=utf-8&useSSL=false
spring.datasource.two.username = root
spring.datasource.two.password = 2171821
spring.datasource.two.type = com.alibaba.druid.pool.DruidDataSource
spring.datasource.two.driver-class-name = com.mysql.jdbc.Driver



##################    连接池配置    ################
#连接池建立时创建的初始化连接数
spring.datasource.one.druid.initial-size=5
#连接池中最大的活跃连接数
spring.datasource.one.druid.max-active=12
#连接池中最小的活跃连接数
spring.datasource.one.druid.min-idle=5
# 配置获取连接等待超时的时间
spring.datasource.one.druid.max-wait=60000
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.one.druid.pool-prepared-statements=true
spring.datasource.one.druid.max-pool-prepared-statement-per-connection-size=20
#spring.datasource.druid.max-open-prepared-statements= #和上面的等价
spring.datasource.one.druid.validation-query=SELECT 1 FROM DUAL
spring.datasource.one.druid.validation-query-timeout=30000
#是否在获得连接后检测其可用性
spring.datasource.one.druid.test-on-borrow=false
#是否在连接放回连接池后检测其可用性
spring.datasource.one.druid.test-on-return=false
#是否在连接空闲一段时间后检测其可用性
spring.datasource.one.druid.test-while-idle=true
#spring.datasource.druid.time-between-eviction-runs-millis=
#spring.datasource.druid.min-evictable-idle-time-millis=
#spring.datasource.druid.max-evictable-idle-time-millis=


##################    连接池配置    ################
#连接池建立时创建的初始化连接数
spring.datasource.two.druid.initial-size=5
#连接池中最大的活跃连接数
spring.datasource.two.druid.max-active=12
#连接池中最小的活跃连接数
spring.datasource.two.druid.min-idle=5
# 配置获取连接等待超时的时间
spring.datasource.two.druid.max-wait=60000
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.two.druid.pool-prepared-statements=true
spring.datasource.two.druid.max-pool-prepared-statement-per-connection-size=20
#spring.datasource.druid.max-open-prepared-statements= #和上面的等价
spring.datasource.two.druid.validation-query=SELECT 1 FROM DUAL
spring.datasource.two.druid.validation-query-timeout=30000
#是否在获得连接后检测其可用性
spring.datasource.two.druid.test-on-borrow=false
#是否在连接放回连接池后检测其可用性
spring.datasource.two.druid.test-on-return=false
#是否在连接空闲一段时间后检测其可用性
spring.datasource.two.druid.test-while-idle=true
#spring.datasource.druid.time-between-eviction-runs-millis=
#spring.datasource.druid.min-evictable-idle-time-millis=
#spring.datasource.druid.max-evictable-idle-time-millis=

#bean所在位置
mybatis.type-aliases-package=com.sstl.sharebike.model
#以下是使用配置文件版本的方法,若使用注解版本,可以删除
##########################  mybatis   ##########################
#mybatis配置文件所在位置
#感觉这个配置文件没起作用，比如用map接收时，即便value为空也保留key 在配置文件中已经配置，也没用
mybatis.config-locations=classpath:mybatis/mybatis-config.xml
#mybatis对应的xml文件所在位置
mybatis.mapper-locations=classpath:mybatis/mapper/*.xml
#用map接收时，即便value为空也保留key
mybatis.configuration.call-setters-on-nulls=true
#配置项：开启下划线到驼峰的自动转换. 作用：将数据库字段根据驼峰规则自动注入到对象属性。
mybatis.configuration.map-underscore-to-camel-case=true
#打印sql语句
#logging.level.com.arviiin.dataquality.mapper=debug
# 配置slq打印日志     当然这个只是为了本地开发调试用的，部署到生产环境，别千万别打开这种sql日志打印啊…
mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl

#配置邮件发送
#邮箱服务器地址
#spring.mail.host=smtp.qq.com
spring.mail.host=smtp.163.com
#用户名
spring.mail.username=data_quality_admin@163.com
#开启POP3之后设置的客户端授权码   这里的password不是登录密码，是开启POP3之后设置的客户端授权码
#spring.mail.password=snpcpokussvebbfg
spring.mail.password=dhu2171821
#默认端口25，使用465端口时，需要添加配置：
spring.mail.port=465
spring.mail.properties.mail.smtp.ssl.enable=true
#编码
spring.mail.default-encoding=UTF-8
spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory
spring.mail.properties.mail.debug=true

#springboot集成kafka集群
# kafka服务器地址(可以多个)
spring.kafka.bootstrap-servers=192.168.52.100:9092,192.168.52.110:9092,192.168.52.120:9092
# 指定一个默认的组名
spring.kafka.consumer.group-id=kafka2
# earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
# latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
# none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=latest
# key/value的反序列化
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# key/value的序列化
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# 批量抓取
spring.kafka.producer.batch-size=65536
# 缓存容量
spring.kafka.producer.buffer-memory=524288






